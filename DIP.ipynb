{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VQm3Es2EBiSL"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless scikit-image scikit-learn matplotlib Pillow seaborn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import scipy.stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from skimage.restoration import denoise_wavelet\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# ------------------------\n",
        "# PARAMETERS\n",
        "# ------------------------\n",
        "DATA_DIR = \"/content/data\"  # <-- update this to your dataset path\n",
        "N_REPEATS = 10\n",
        "USE_COMPRESSION = False  # Set to True for JPEG compression test\n",
        "IMAGE_SIZE = (768, 1024)  # Width x Height\n",
        "label_map = {0: \"Scanner\", 1: \"Computer Generated\", 2: \"Camera\"}\n",
        "\n",
        "# ------------------------\n",
        "# RESIDUAL NOISE FEATURE EXTRACTION\n",
        "# ------------------------\n",
        "def extract_features(img):\n",
        "    if len(img.shape) == 3:\n",
        "        img = img[:, :, 1]  # green channel\n",
        "\n",
        "    denoised = denoise_wavelet(img, channel_axis=None, rescale_sigma=True)\n",
        "    noise = img.astype(np.float32) - denoised.astype(np.float32)\n",
        "\n",
        "    M, N = noise.shape\n",
        "    r_avg = np.mean(noise, axis=0)\n",
        "    c_avg = np.mean(noise, axis=1)\n",
        "\n",
        "    def normalized_corr(a, b):\n",
        "        if np.std(a) == 0 or np.std(b) == 0:\n",
        "            return 0\n",
        "        return np.corrcoef(a, b)[0, 1]\n",
        "\n",
        "    rho_row = [normalized_corr(r_avg, noise[i, :]) for i in range(M)]\n",
        "    rho_col = [normalized_corr(c_avg, noise[:, j]) for j in range(N)]\n",
        "\n",
        "    f = [\n",
        "        np.mean(rho_row), np.std(rho_row),\n",
        "        scipy.stats.skew(rho_row), scipy.stats.kurtosis(rho_row),\n",
        "        np.mean(rho_col), np.std(rho_col),\n",
        "        scipy.stats.skew(rho_col), scipy.stats.kurtosis(rho_col),\n",
        "        np.std(r_avg), scipy.stats.skew(r_avg), scipy.stats.kurtosis(r_avg),\n",
        "        np.std(c_avg), scipy.stats.skew(c_avg), scipy.stats.kurtosis(c_avg),\n",
        "        (1 - np.mean(rho_col) / np.mean(rho_row)) * 100\n",
        "    ]\n",
        "\n",
        "    return f\n",
        "\n",
        "# ------------------------\n",
        "# JPEG COMPRESSION FUNCTION\n",
        "# ------------------------\n",
        "def jpeg_compress_image(cv2_img, quality=90):\n",
        "    rgb_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)\n",
        "    pil_img = Image.fromarray(rgb_img)\n",
        "    buffer = BytesIO()\n",
        "    pil_img.save(buffer, format='JPEG', quality=quality)\n",
        "    buffer.seek(0)\n",
        "    jpeg_img = Image.open(buffer)\n",
        "    jpeg_arr = np.array(jpeg_img)\n",
        "    return cv2.cvtColor(jpeg_arr, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# ------------------------\n",
        "# LOAD DATASET\n",
        "# ------------------------\n",
        "def load_dataset(data_dir, compress=False):\n",
        "    X, y = [], []\n",
        "    labels = {'scanner': 0, 'cg': 1, 'camera': 2}\n",
        "    for label_name, label_value in labels.items():\n",
        "        folder = os.path.join(data_dir, label_name)\n",
        "        for fname in os.listdir(folder):\n",
        "            if fname.lower().endswith(('.jpg', '.png', '.jpeg', '.tif')):\n",
        "                path = os.path.join(folder, fname)\n",
        "                img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "                img = cv2.resize(img, IMAGE_SIZE)\n",
        "                if compress:\n",
        "                    img = jpeg_compress_image(img, quality=90)\n",
        "                f = extract_features(img)\n",
        "                X.append(f)\n",
        "                y.append(label_value)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# ------------------------\n",
        "# MAIN TRAINING LOOP\n",
        "# ------------------------\n",
        "print(\"Loading dataset (compression: {})...\".format(USE_COMPRESSION))\n",
        "X, y = load_dataset(DATA_DIR, compress=USE_COMPRESSION)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "splitter = StratifiedShuffleSplit(n_splits=N_REPEATS, test_size=0.2, random_state=42)\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "conf_matrices = []\n",
        "\n",
        "print(\"Running {} repetitions with GridSearchCV...\".format(N_REPEATS))\n",
        "\n",
        "for i, (train_idx, test_idx) in enumerate(splitter.split(X_scaled, y)):\n",
        "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    grid = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=3, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    model = grid.best_estimator_\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    acc_train = accuracy_score(y_train, y_train_pred)\n",
        "    acc_test = accuracy_score(y_test, y_test_pred)\n",
        "    cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    train_accuracies.append(acc_train)\n",
        "    test_accuracies.append(acc_test)\n",
        "    conf_matrices.append(cm)\n",
        "\n",
        "    print(\"Run {}: Train = {:.2f}%, Test = {:.2f}% | Best Params: {}\".format(\n",
        "        i + 1, acc_train * 100, acc_test * 100, grid.best_params_\n",
        "    ))\n",
        "\n",
        "print(\"\\n===== Summary =====\")\n",
        "print(\"Average Training Accuracy: {:.2f}%\".format(np.mean(train_accuracies) * 100))\n",
        "print(\"Average Testing Accuracy: {:.2f}%\".format(np.mean(test_accuracies) * 100))\n",
        "print(\"Standard Deviation (Test): {:.2f}%\".format(np.std(test_accuracies) * 100))\n",
        "\n",
        "avg_cm = np.mean(conf_matrices, axis=0)\n",
        "sns.heatmap(avg_cm, annot=True, fmt=\".1f\", cmap=\"Blues\",\n",
        "            xticklabels=list(label_map.values()),\n",
        "            yticklabels=list(label_map.values()))\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Average Confusion Matrix ({} runs)\".format(N_REPEATS))\n",
        "plt.show()\n",
        "\n",
        "# ------------------------\n",
        "# TRAIN FINAL MODEL ON FULL DATA\n",
        "# ------------------------\n",
        "grid_final = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=3, n_jobs=-1)\n",
        "grid_final.fit(X_scaled, y)\n",
        "final_model = grid_final.best_estimator_\n",
        "\n",
        "# ------------------------\n",
        "# CLASSIFY NEW IMAGE FUNCTION\n",
        "# ------------------------\n",
        "def classify_image(image_path, model, scaler, compress=False):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, IMAGE_SIZE)\n",
        "    if compress:\n",
        "        img = jpeg_compress_image(img, quality=90)\n",
        "    features = extract_features(img)\n",
        "    features_scaled = scaler.transform([features])\n",
        "    pred = model.predict(features_scaled)[0]\n",
        "    return label_map[pred]\n",
        "\n",
        "# ------------------------\n",
        "# EXAMPLE CLASSIFICATION\n",
        "# ------------------------\n",
        "# Upload a test image or provide a path and run:\n",
        "# image_path = \"/content/sample_image.jpg\"\n",
        "# result = classify_image(image_path, final_model, scaler, compress=True)\n",
        "# print(\"Predicted Source:\", result)"
      ],
      "metadata": {
        "id": "qsephvXEBkz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/sample_image.jpg\"\n",
        "result = classify_image(image_path, final_model, scaler, compress=False)\n",
        "print(\"Predicted Source:\", result)"
      ],
      "metadata": {
        "id": "zamb3EesBwbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}